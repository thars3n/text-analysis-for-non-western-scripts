{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and set up logging\n",
    "import gensim \n",
    "import logging\n",
    "import glob, os\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing all source texts for training the model \n",
    "data_dir=\"../corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1H4_h.txt = 130423 chars\n",
      "1H6_h.txt = 116317 chars\n",
      "2H4_h.txt = 141574 chars\n",
      "2H6_h.txt = 135863 chars\n",
      "3H6_h.txt = 129551 chars\n",
      "Ado_c.txt = 111116 chars\n",
      "Ant_t.txt = 133668 chars\n",
      "AWW_c.txt = 121896 chars\n",
      "AYL_c.txt = 114429 chars\n",
      "Cor_t.txt = 146443 chars\n",
      "Cym_t.txt = 147159 chars\n",
      "Err_c.txt = 76924 chars\n",
      "H5_h.txt = 141819 chars\n",
      "H8_h.txt = 128223 chars\n",
      "Ham_t.txt = 163429 chars\n",
      "JC_t.txt = 104561 chars\n",
      "John_t.txt = 112414 chars\n",
      "Lear_t.txt = 140510 chars\n",
      "LLL_c.txt = 115391 chars\n",
      "Lucrece_x.txt = 86177 chars\n",
      "M4M_c.txt = 116348 chars\n",
      "Mac_t.txt = 91625 chars\n",
      "MerchV_c.txt = 112334 chars\n",
      "MND_c.txt = 88608 chars\n",
      "Oth_t.txt = 141395 chars\n",
      "Pericles_x.txt = 97471 chars\n",
      "PhxTur_x.txt = 2072 chars\n",
      "R2_h.txt = 120934 chars\n",
      "R3_h.txt = 156881 chars\n",
      "Rom_t.txt = 130885 chars\n",
      "Shr_c.txt = 111364 chars\n",
      "Sonnets_x.txt = 97204 chars\n",
      "TGV_c.txt = 91686 chars\n",
      "Tim_t.txt = 98749 chars\n",
      "Tit_t.txt = 109892 chars\n",
      "Tmp_c.txt = 88800 chars\n",
      "TN_c.txt = 104476 chars\n",
      "TNK_x.txt = 127691 chars\n",
      "Tro_c.txt = 142635 chars\n",
      "VenusAdonis_x.txt = 55527 chars\n",
      "Wiv_c.txt = 115202 chars\n",
      "WT_c.txt = 134528 chars\n"
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir)\n",
    "documents = list()\n",
    "for filename in glob.glob(\"*.txt\"):\n",
    "    filedata = open(filename, 'r').read()\n",
    "    print(filename + \" = \" + str(len(filedata)) + \" chars\")\n",
    "    documents = documents + filedata.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " So shaken as we are , so wan with care , Find we a time for frighted peace to pant And breathe short-winded accents of new broils To be commenced in strands afar remote \n"
     ]
    }
   ],
   "source": [
    "# Check to see that the first sentence is correct\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-07 15:27:01,570 : INFO : collecting all words and their counts\n",
      "2019-05-07 15:27:01,571 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2019-05-07 15:27:01,960 : INFO : PROGRESS: at sentence #10000, processed 205010 words and 101389 word types\n",
      "2019-05-07 15:27:02,342 : INFO : PROGRESS: at sentence #20000, processed 403566 words and 170975 word types\n",
      "2019-05-07 15:27:02,712 : INFO : PROGRESS: at sentence #30000, processed 599588 words and 233068 word types\n",
      "2019-05-07 15:27:03,096 : INFO : PROGRESS: at sentence #40000, processed 798141 words and 286447 word types\n",
      "2019-05-07 15:27:03,471 : INFO : PROGRESS: at sentence #50000, processed 998259 words and 337166 word types\n",
      "2019-05-07 15:27:03,708 : INFO : collected 365018 word types from a corpus of 1107953 words (unigram + bigrams) and 55651 sentences\n",
      "2019-05-07 15:27:03,709 : INFO : using 365018 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2019-05-07 15:27:03,710 : INFO : source_vocab length 365018\n",
      "2019-05-07 15:27:07,660 : INFO : Phraser built with 1137 phrasegrams\n",
      "2019-05-07 15:27:07,674 : INFO : collecting all words and their counts\n",
      "2019-05-07 15:27:07,676 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2019-05-07 15:27:08,636 : INFO : PROGRESS: at sentence #10000, processed 177937 words and 100651 word types\n",
      "2019-05-07 15:27:09,522 : INFO : PROGRESS: at sentence #20000, processed 350165 words and 171156 word types\n",
      "2019-05-07 15:27:10,372 : INFO : PROGRESS: at sentence #30000, processed 520407 words and 233881 word types\n",
      "2019-05-07 15:27:11,194 : INFO : PROGRESS: at sentence #40000, processed 692661 words and 288512 word types\n",
      "2019-05-07 15:27:12,064 : INFO : PROGRESS: at sentence #50000, processed 866443 words and 340596 word types\n",
      "2019-05-07 15:27:12,599 : INFO : collected 369042 word types from a corpus of 961298 words (unigram + bigrams) and 55651 sentences\n",
      "2019-05-07 15:27:12,600 : INFO : using 369042 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2019-05-07 15:27:12,600 : INFO : source_vocab length 369042\n",
      "2019-05-07 15:27:16,753 : INFO : Phraser built with 2603 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "#documents = [\"the mayor of new york was there\", \"human computer interaction and machine learning has now become a trending research area\",\"human computer interaction is interesting\",\"human computer interaction is a pretty interesting subject\", \"human computer interaction is a great and new subject\", \"machine learning can be useful sometimes\",\"new york mayor was present\", \"I love machine learning because it is a new subject area\", \"human computer interaction helps people to get user friendly applications\"]\n",
    "\n",
    "sentence_stream = [doc.split(\" \") for doc in documents]\n",
    "\n",
    "trigram_sentences_project = []\n",
    "\n",
    "#bigram = Phrases(sentence_stream, min_count=1, delimiter=b' ')\n",
    "#trigram = Phrases(bigram[sentence_stream], min_count=1, delimiter=b' ')\n",
    "#bigram = Phrases(sentence_stream, min_count=1, delimiter=b' ', threshold=2)\n",
    "#trigram = Phrases(bigram[sentence_stream], min_count=1, delimiter=b' ') #, threshold=3\n",
    "\n",
    "bigram = Phraser(Phrases(sentence_stream))\n",
    "trigram = Phraser(Phrases(bigram[sentence_stream]))\n",
    "\n",
    "for sent in sentence_stream:\n",
    "    bigrams_ = bigram[sent]\n",
    "    trigrams_ = trigram[bigram[sent]]\n",
    "    trigram_sentences_project.append(trigrams_)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 200    # Word vector dimensionality                      \n",
    "min_word_count = 1    # Minimum word count                        \n",
    "num_workers = 20      # Number of threads to run in parallel\n",
    "context = 5           # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "model = word2vec.Word2Vec(trigram_sentences_project, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "vocab = list(model.wv.vocab.keys())\n",
    "print(vocab[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of items in our model's vocabulary\n",
    "print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"king\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"lady\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"death\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.relative_cosine_similarity(\"lady\",\"lord\",topn=10))\n",
    "print(model.wv.relative_cosine_similarity(\"lady\",\"meal\",topn=10))\n",
    "# From the gensim documentation: \"For WordNet synonyms, if rcs(topn=10) is greater than 0.10 \n",
    "# then wa and wb are more similar than any arbitrary word pairs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analogies -- this example asks:\n",
    "# \"she\" is to \"sings\" as \"he\" is to ...   (analogies are often written like this: \"she:sings::he:?\")\n",
    "model.wv.most_similar(positive=['she','sings'],negative=['he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_output_word([\"I\",\"do\",\"love\"], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
